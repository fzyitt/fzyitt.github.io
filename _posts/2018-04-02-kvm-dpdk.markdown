---
layout:     post
title:      Using Openvswitch with dpdk in qemu-kvm
subtitle:   Setup compare groups with and without dpdk
date:       2018-4-2
author:     Fan Zhongyi
catalog: true
tags:
    - Openvswitch
    - DPDK
    - qemu-kvm
    - guestfish
---

# Using Openvswitch with dpdk in qemu-kvm
This wiki introduces how to configure qemu-kvm integrated in Openvswitch with and without DPDK.

## Setup requirements

* DPDK 17.05
* Openvswitch 2.8.2
* Ubuntu 16.04 LTS
* qemu-system-x86_64 2.5.0
* VM image: xenial server cloud image
* **Network Interface Card**: Inter I219-V (which should be supported by DPDK)

## Configure Ubuntu cloud image

As the up to date version of Ubuntu cloud image, there is no default user and password. The only way to 
log into these kind of images is ssh with public keys shown in first boot logging. However the situation
is that i want to log into this without network pre-setting image in my terminal. Then the way is to change
cloud.cfg with guestfish.

``` shell
# install guestfish in ubuntu 16.04
sudo apt install libguestfs-tools

# open image file with guestfish
guestfish --rw -a xenial-server-cloudimg-amd64-disk1.img

# then inside guestfish terminal
><fs> run
><fs> list-filesystems
/dev/sda1: ext4
><fs> mount /dev/sda1

# after mount, edit cloud.cfg
vi /etc/cloud/cloud.cfg
```

After getting inside image configuration file, remember to change these parameters:

``` shell
lock_passwd: True  --> lock_passwd: False

# add a line link below, the passwd can not be plain text, so it is generated with openssl as the plaintext 'secret'
passwdï¼š$1$SaltSalt$YhgRYajLPrYevs14poKBQ0
```

Then quit the guestfish, it is possible for us to login the image with username:ubuntu and passwd:secret

## Install and configure DPDK with Openvswitch

### Install DPDK and Openvswitch on host

Since DPDK will consume hugepage, host machine should support hugepage, which should also be well configured.

``` shell
# download specfic version of DPDK package from dpdk.org
wget http://dpdk.org/browse/dpdk/snapshot/dpdk-17.05.tar.gz
tar -zxvf dpdk-17.05.tar.gz

# configure DPDK
cd dpdk-17.05/
mkdir -p /usr/src/dpdk
make config T=x86_64-native-linuxapp-gcc

# destination dir of DPDK for ovs
make install T=x86_64-native-linuxapp-gcc DESTDIR=/usr/src/dpdk

# install DPDK
make install T=x86_64-native-linuxapp-gcc DESTDIR=/usr
```

Then there is an important point that, Openvswitch version shold be compatible with responding DPDK version.

``` shell
# download specific version of Openvswitch package from openvswitch.org
wget http://openvswitch.org/releases/openvswitch-2.8.2.tar.gz
tar -zxvf openvswitch-2.8.2.tar.gz

# compile openvswitch
cd openvswitch-2.8.2/
./boot.sh
./configure \
--with-dpdk=/usr/src/dpdk \
--prefix=/usr \
--exec-prefix=/usr \
--sysconfdir=/etc \
--localstatedir=/var

# make install
make
make install
```

### Configure DPDK and Hugepage

#### 1. Configure Hugepage

Enough hugepage should be preserved, since vhost-user interface will consume them.

``` shell
# check hugepage setting
cat /etc/proc/meminfo | grep Huge

# set hugepage temporarily
echo 1024 > /proc/sys/vm/nr_hugepages

# set hugepage permantly
echo 'vm.nr_hugepages=1024' > /etc/sysctl.d/hugepages.conf

# mount hugepages
mount -t hugetlbfs none /dev/hugepages
```

#### 2. Start openvswitch deamon

``` shell
# create openvswitch path
mkdir -p /etc/openvswiwtch
mkdir -p /var/run/openvswitch

# start openvswitch server
ovsdb-server /etc/openvswitch/conf.db \
-vconsole:emer -vsyslog:err -vfile:info \
--remote=punix:/var/run/openvswitch/db.sock \
--private-key=db:Open_vSwitch,SSL,private_key \
--certificate=db:Open_vSwitch,SSL,certificate \
--bootstrap-ca-cert=db:Open_vSwitch,SSL,ca_cert --no-chdir \
--log-file=/var/log/openvswitch/ovsdb-server.log \
--pidfile=/var/run/openvswitch/ovsdb-server.pid \
--detach --monitor

# initialize for the first time starting openvswitch
ovs-vsctl --no-wait init

# initialize openvswitch with DPDK
ovs-vsctl --no-wait set Open_vswitch . other-config:dpdk-init=true
ovs-vsctl --no-wait set Open_vswitch . other-config:dpdk-socket-mem="128,128"

# start openvswicth deamon
ovs-vswitchd unix:/var/run/openvswitch/db.sock \
-vconsole:emer -vsyslog:err -vfile:info --mlockall --no-chdir \
--log-file=/var/log/openvswitch/ovs-vswitchd.log \
--pidfile=/var/run/openvswitch/ovs-vswitchd.pid \
--detach --monitor
```

#### 3. Bind pythsical network interface card to DPDK

``` shell
# make sure to open VT-d ,iommu and intel_iommu to support vfio and igb-uio
vim /boot/grub/grub.cfg
add iommu=pt intel_iommu=on behind boot cmdline

# load dpdk driver
modprobe uio
insmod dpdk-17.05/x86_64-native-linuxapp-gcc/kmod/igb_uio.ko

# check dpdk bind status and copy the pci number of the interface which is going to bind to DPDK
dpdk-devbind --status

# bind
dpdk-devbind --bind=uio_igb 0000:00:1f.6
```
Then this interface will be used to forwarding packets for DPDK.

After all setting upon, openvswitch with DPDK will be successfully configured and running on host.

## Create qemu-kvm and connect to ovs-dpdk

### Create ovs-dpdk bridge and vhost-user port

``` shell
sudo ovs-vsctl add-br br0 -- set bridge br0 datapath_type=netdev
sudo ovs-vsctl add-port br0 vhost-user1 -- set Interface vhost-user1 type=dpdkvhostuser
sudo ovs-vsctl add-port br0 vhost-user2 -- set Interface vhost-user2 type=dpdkvhostuser
```

### Launch VM with DPDK vhost-user port

``` shell
sudo qemu-system-x86_64 -m 512 -smp 4 -cpu host -hda /home/vm/Downloads/ubuntu-16.04-server-cloudimg-amd64-disk1.img -boot c -enable-kvm -no-reboot -net none -nographic -chardev socket,id=char1,path=/run/openvswitch/vhost-user1 -netdev type=vhost-user,id=mynet1,chardev=char1,vhostforce -device virtio-net-pci,mac=00:00:00:00:00:01,netdev=mynet1 -object memory-backend-file,id=mem,size=512M,mem-path=/dev/hugepages,share=on -numa node,memdev=mem -mem-prealloc
```

This is the template for lauching qemu-kvm VM with DPDK vhost-user interface. For more VM to lauch, just change some parameters and boot VM on another
terminal.

When log in VM with password set before, remember to configure network settings in VM to ensure connection between host and VM, and even the Internet.

### Lauch VM with normal port

``` shell
qemu-system-x86_64 -m 512 -smp 4 -cpu host -hda /home/vm/Downloads/ubuntu-16.04-server-cloudimg-amd64-disk4.img -boot c -enable-kvm -no-reboot -net none -nographic -net nic,macaddr=00:00:00:00:00:03 -net tap,ifname=vm1,script=no,downscript=no

sudo ovs-vsctl add-port br0 vm1
```

Similar network setting should also be set in normal VM.

